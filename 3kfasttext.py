# -*- coding: utf-8 -*-
"""3kfasttext.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zzBsiJDD3FLhJDM3SmSkvWTVE6F33mBR
"""

!pip install fasttext
import fasttext
import pandas as pd
from pandas import DataFrame as df
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from mlxtend.plotting import plot_confusion_matrix
from bs4 import BeautifulSoup
import os
import re
!pip install emoji
import emoji
from io import StringIO, BytesIO
from google.colab import drive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive

def load_dict_smileys():
    return {
        ":‑)":"gülücük",
        ":-]":"gülücük",
        ":-3":"gülücük",
        ":->":"gülücük",
        "8-)":"gülücük",
        ":-}":"gülücük",
        ":)":"gülücük",
        ":]":"gülücük",
        ":3":"gülücük",
        ":>":"gülücük",
        "8)":"gülücük",
        ":}":"gülücük",
        ":o)":"gülücük",
        ":c)":"gülücük",
        ":^)":"gülücük",
        "=]":"gülücük",
        "=)":"gülücük",
        ":-))":"gülücük",
        ":‑D":"gülücük",
        "8‑D":"gülücük",
        "x‑D":"gülücük",
        "X‑D":"gülücük",
        ":D":"gülücük",
        "8D":"gülücük",
        "xD":"gülücük",
        "XD":"gülücük",
        ":‑(":"üzgün",
        ":‑c":"üzgün",
        ":‑<":"üzgün",
        ":‑[":"üzgün",
        ":(":"üzgün",
        ":c":"üzgün",
        ":<":"üzgün",
        ":[":"üzgün",
        ":-||":"üzgün",
        ">:[":"üzgün",
        ":{":"üzgün",
        ":@":"üzgün",
        ">:(":"üzgün",
        ":'‑(":"üzgün",
        ":'(":"üzgün",
        ":‑P":"eğlenceli",
        "X‑P":"eğlenceli",
        "x‑p":"eğlenceli",
        ":‑p":"eğlenceli",
        ":‑Þ":"eğlenceli",
        ":‑þ":"eğlenceli",
        ":‑b":"eğlenceli",
        ":P":"eğlenceli",
        "XP":"eğlenceli",
        "xp":"eğlenceli",
        ":p":"eğlenceli",
        ":Þ":"eğlenceli",
        ":þ":"eğlenceli",
        ":b":"eğlenceli",
        "<3":"sevgi"
        }
def cumleyiarindir(tweet):
    tweet = BeautifulSoup(tweet).get_text()
    tweet = tweet.replace('\x92',"'")
    tweet = ' '.join(re.sub("(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)", " ", tweet).split())
    tweet = ' '.join(re.sub("(\w+://\S+)", " ", tweet).split())
    tweet = ' '.join(re.sub("[.,!?:;-=]", " ", tweet).split())
    tweet = tweet.lower()
    SMILEY = load_dict_smileys()
    words = tweet.split()
    reformed = [SMILEY[word] if word in SMILEY else word 
    for word in words]
    tweet = " ".join(reformed)
    tweet = emoji.demojize(tweet)
    tweet = tweet.replace(":"," ")
    tweet = ' '.join(tweet.split())
    return tweet

texts=""
labels = []

folders=[ '1','2', '3']
filename='/content/drive/My Drive/Colab Notebooks/raw_texts/'
for x in folders:
    tweet_count=0
    if(x=='1'):
      lbl = "__label__olumlu "
    if(x=='2'):
      lbl = "__label__olumsuz "
    if(x=='3'):
      lbl = "__label__notr "
    path=os.path.join(filename, x)
    for t in os.listdir(path):
        tweetcount+=1
        p2=os.path.join(path,t)
        f=open(p2, "r", encoding="cp1254")
        f=cumleyiarindir(f)
        txt=lbl+f+"\n"
        texts+=txt



dosya=open('ortaknew.csv', 'w', encoding="utf8")
dosya.write(texts)
dosya.close()

#a=['sentence','Label']
#data = pd.read_csv('ortak.csv',header=None, engine='python',sep=';',names=a, encoding='cp1254')
#print(data)

#fp = open('ortaknew.csv','w',encoding='utf-8')

#for i in range(len(x)):
 #   x=cumleyiarindir(x[i])
  #  newSentence = '__label__'+ (y[i]) +' '+ x +'\n'.lower()
   # fp.write(newSentence)

from sklearn.model_selection import train_test_split
txts=[]
lbls=[]
pred_test=[]
true_labels=[]
with open('ortaknew.csv', 'r', encoding="utf-8") as f:
  for line in f:
    y,x =line.split(' ', 1)
    txts.append(x)

    lbls.append(y)
x_train, x_test, y_train, y_test = train_test_split(txts, lbls, test_size = 0.7)
fp = open('ortaknew2.csv','w',encoding='utf8')
for i in range(len(x_train)):
  sntce=y_train[i]+ ' '+x_train[i]
  fp.write(sntce)
for i in range(len(x_test)):
  sntce=y_test[i]+ ' '+x_test[i]
  pred_test.append(x_test[i][:-1])
  true_labels.append(y_test[i])

  fp.write(sntce)
print(len(true_labels))
fp.close()

k = []
s = []

def ayir(dosya, textsize):
    num_lines=sum(1 for line in open(dosya))
    count=0
    train=""
    test=""
    with open(dosya, 'r', encoding='utf-8') as f:
        for line in f:
            if(count<(num_lines/100)*(100-textsize)):
                train+=line
            else:
                
         
              
                test+=line
            count+=1
    dosya=open('train1.txt','w', encoding="utf-8")
    dosya.write(train)
    dosya.close()
    dosya=open('test1.txt','w', encoding="utf-8")
    dosya.write(test)
    dosya.close()
    print(k)
    print(s)


ayir('ortaknew.csv',20)

model = fasttext.train_supervised(input='train1.txt', epoch=25, lr=0.1, wordNgrams=2, loss='hs',dim=100)

model.predict("çok iyi",k=3)

from mlxtend.plotting import plot_confusion_matrix
rounded_pred = model.predict(pred_test, k=1)
print(rounded_pred[0][1])

print(confusion_matrix(true_labels,rounded_pred[0]))
print(plot_confusion_matrix(conf_mat=confusion_matrix(true_labels,rounded_pred[0])))

total_acc=0
for i in range(len(rounded_pred[0])):

  if rounded_pred[0][i][0]==true_labels[i]:
    total_acc+=1
print("Accuracy : " ,total_acc/len(rounded_pred[0]))