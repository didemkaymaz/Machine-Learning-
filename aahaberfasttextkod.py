# -*- coding: utf-8 -*-
"""Aahaberfasttextkod.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1llwCqhqW-KqgwTvOkeqNrcqms7vPzXwO
"""

!pip install fasttext
import fasttext
import pandas as pd
from pandas import DataFrame as df
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from mlxtend.plotting import plot_confusion_matrix
from bs4 import BeautifulSoup
import os
import re
!pip install emoji
import emoji

def load_dict_smileys():
    return {
        ":‑)":"gülücük",
        ":-]":"gülücük",
        ":-3":"gülücük",
        ":->":"gülücük",
        "8-)":"gülücük",
        ":-}":"gülücük",
        ":)":"gülücük",
        ":]":"gülücük",
        ":3":"gülücük",
        ":>":"gülücük",
        "8)":"gülücük",
        ":}":"gülücük",
        ":o)":"gülücük",
        ":c)":"gülücük",
        ":^)":"gülücük",
        "=]":"gülücük",
        "=)":"gülücük",
        ":-))":"gülücük",
        ":‑D":"gülücük",
        "8‑D":"gülücük",
        "x‑D":"gülücük",
        "X‑D":"gülücük",
        ":D":"gülücük",
        "8D":"gülücük",
        "xD":"gülücük",
        "XD":"gülücük",
        ":‑(":"üzgün",
        ":‑c":"üzgün",
        ":‑<":"üzgün",
        ":‑[":"üzgün",
        ":(":"üzgün",
        ":c":"üzgün",
        ":<":"üzgün",
        ":[":"üzgün",
        ":-||":"üzgün",
        ">:[":"üzgün",
        ":{":"üzgün",
        ":@":"üzgün",
        ">:(":"üzgün",
        ":'‑(":"üzgün",
        ":'(":"üzgün",
        ":‑P":"eğlenceli",
        "X‑P":"eğlenceli",
        "x‑p":"eğlenceli",
        ":‑p":"eğlenceli",
        ":‑Þ":"eğlenceli",
        ":‑þ":"eğlenceli",
        ":‑b":"eğlenceli",
        ":P":"eğlenceli",
        "XP":"eğlenceli",
        "xp":"eğlenceli",
        ":p":"eğlenceli",
        ":Þ":"eğlenceli",
        ":þ":"eğlenceli",
        ":b":"eğlenceli",
        "<3":"sevgi"
        }
def cumleyiarindir(tweet):
    tweet = BeautifulSoup(tweet).get_text()
    tweet = tweet.replace('\x92',"'")
    tweet = ' '.join(re.sub("(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)", " ", tweet).split())
    tweet = ' '.join(re.sub("(\w+://\S+)", " ", tweet).split())
    tweet = ' '.join(re.sub("[.,!?:;-=]", " ", tweet).split())
    tweet = tweet.lower()
    SMILEY = load_dict_smileys()
    words = tweet.split()
    reformed = [SMILEY[word] if word in SMILEY else word 
    for word in words]
    tweet = " ".join(reformed)
    tweet = emoji.demojize(tweet)
    tweet = tweet.replace(":"," ")
    tweet = ' '.join(tweet.split())
    return tweet

a=['gereksiz','Label','sentence']
data = pd.read_csv('aahaber.csv',header=None, engine='python',sep=';',names=a, encoding='cp1254')
print(data)

fp = open('ortaknew.csv','w',encoding='utf-8')

for i in range(len(data)):
    x=cumleyiarindir(data.sentence[i])
    
    newSentence = '__label__'+ str(data. Label[i]) +' '+ x +'\n'.lower()
    fp.write(newSentence)

from sklearn.model_selection import train_test_split
txts=[]
lbls=[]
pred_test=[]
true_labels=[]
with open('ortaknew.csv', 'r', encoding="utf-8") as f:
  for line in f:
    y,x =line.split(' ', 1)
    txts.append(x)

    lbls.append(y)
x_train, x_test, y_train, y_test = train_test_split(txts, lbls, test_size = 0.7)
fp = open('ortaknew2.csv','w',encoding='utf8')
for i in range(len(x_train)):
  sntce=y_train[i]+ ' '+x_train[i]
  fp.write(sntce)
for i in range(len(x_test)):
  sntce=y_test[i]+ ' '+x_test[i]
  pred_test.append(x_test[i][:-1])
  true_labels.append(y_test[i])

  fp.write(sntce)
print(true_labels)
fp.close()

k = []
s = []

def ayir(dosya, textsize):
    num_lines=sum(1 for line in open(dosya))
    count=0
    train=""
    test=""
    with open(dosya, 'r', encoding='utf-8') as f:
        for line in f:
            if(count<(num_lines/100)*(100-textsize)):
                train+=line
            else:
                
                x,y= line.split(' ',1)
                k.append(x)
                
                s.append(y[:-1])
              
                test+=line
            count+=1
    dosya=open('train1.txt','w', encoding="utf-8")
    dosya.write(train)
    dosya.close()
    dosya=open('test1.txt','w', encoding="utf-8")
    dosya.write(test)
    dosya.close()
    print(k)
    print(s)


ayir('ortaknew2.csv',20)

model = fasttext.train_supervised(input='train1.txt', epoch=25,lr=0.1, wordNgrams=2, loss='hs',dim=100)

model.predict("çevre ve orman bakanlığı akdeniz ve ege sahillerinde bulunan otel ve tatil köylerinin denizlerde canlı ekosistemin bozulması kirlilik açısından kıyı kaynakları üzerinde önemli etkileri bulunduğu bildirildi",k=3)

from mlxtend.plotting import plot_confusion_matrix
rounded_pred = model.predict(pred_test, k=1)
print(rounded_pred[0][1])

print(confusion_matrix(true_labels,rounded_pred[0]))
print(plot_confusion_matrix(conf_mat=confusion_matrix(true_labels,rounded_pred[0])))

total_acc=0
for i in range(len(rounded_pred[0])):

  if rounded_pred[0][i][0]==true_labels[i]:
    total_acc+=1
print("Accuracy : " ,total_acc/len(rounded_pred[0]))